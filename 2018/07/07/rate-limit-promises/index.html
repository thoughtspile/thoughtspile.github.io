<!DOCTYPE html><html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="HandheldFriendly" content="True"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="yandex-verification" content="635edef3908320be"><link href="/ru/2018/07/07/rate-limit-promises/" rel="alternate" hreflang="ru"><meta name="google-site-verification" content="5nfOA5k_QcuAP9zbAASIV24DlAZG7BWxRVYoNlKCAoc"><meta name="description" content="In the previous post we learnt to serializeand concurrecy-limit promise-based operations in js. This time we dive furtherand handle rate limiting. What Exactly to Rate LimitLet’s get terminological ma"><meta property="og:type" content="article"><meta property="og:title" content="Advanced Promise Coordination: Rate Limiting"><meta property="og:url" content="https://thoughtspile.github.io/2018/07/07/rate-limit-promises/index.html"><meta property="og:site_name" content="Vladimir Klepov as a Coder"><meta property="og:description" content="In the previous post we learnt to serializeand concurrecy-limit promise-based operations in js. This time we dive furtherand handle rate limiting. What Exactly to Rate LimitLet’s get terminological ma"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2018-07-07T07:11:13.000Z"><meta property="article:modified_time" content="2022-01-14T13:29:55.463Z"><meta property="article:author" content="Vladimir Klepov"><meta property="article:tag" content="javascript"><meta property="article:tag" content="programming"><meta property="article:tag" content="promises"><meta property="article:tag" content="high availability"><meta name="twitter:card" content="summary"><link rel="shortcut icon" href="/images/favicon-6e00c3b618952d5cd6e8942e95a692e1.ico"><link rel="icon" type="image/png" href="/images/favicon-192x192-8b6cc8287c442b221bad9ed73e85331f.png" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-53bb79233c939b7e4a27b36cab6aec28.png"><title>Advanced Promise Coordination: Rate Limiting</title><link rel="stylesheet" href="/css/style-6e9addb688f39c95eacb80fa9a450361.css"><link rel="canonical" href="https://thoughtspile.github.io/2018/07/07/rate-limit-promises/"><link rel="alternate" href="/atom.xml" title="Vladimir Klepov as a Coder" type="application/atom+xml"><meta name="generator" content="Hexo 5.4.0"></head><body class="max-width mx-auto px3"><div class="content index"><a href="/" id="header" class="header header--post"><div id="logo"></div><header id="title"><h1>Vladimir Klepov as a Coder</h1></header></a><article class="post" itemscope itemtype="http://schema.org/BlogPosting"><header><h1 class="posttitle" itemprop="name headline">Advanced Promise Coordination: Rate Limiting</h1></header><div class="content" itemprop="articleBody"><p>In the <a href="/2018/06/20/serialize-promises/">previous post</a> we learnt to serialize<br>and concurrecy-limit promise-based operations in js. This time we dive further<br>and handle rate limiting.</p><h2 id="What-Exactly-to-Rate-Limit"><a href="#What-Exactly-to-Rate-Limit" class="headerlink" title="What Exactly to Rate Limit"></a>What Exactly to Rate Limit</h2><p>Let’s get terminological matters out of the way first. Promises represent operations<br>that last a certain amount of time, while rate limiting is applied to discrete events.<br>Over its life, a promise starts and terminates (with a success or a failure, not<br>important now). It makes most sense to rate limit promise creations (starts).<br>Rate limiting promise resolutions can be done by appending a start-rate-limited<br>promise onto the end of the running promise. We could also limit the gap<br>between operations, but I have no idea how that would be useful.</p><h2 id="Rate-vs-concurrency-limiting"><a href="#Rate-vs-concurrency-limiting" class="headerlink" title="Rate vs concurrency limiting"></a>Rate vs concurrency limiting</h2><p>While both rate and concurrency limits are trying to prevent a client from<br>overloading the server by making too many calls too fast, they do not replace<br>one another, and are implemented differently.</p><p>Suppose an API is rate-limited to 1 request per second. Even 1-concurrent requests<br>break the rate limit if they complete in under 1s. On the other hand, if the<br>requests take 3 seconds to complete, we can only have 3 of them running at the same time:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"> ...</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>We could derive a bunch of formulae to connect the concurrency, rate and<br>running time of operations, but that’s completely beside the point. The thing to<br>remember here is that without strict guarantees on operation duration you can<br>not replace concurrency limit with rate limit or vice versa.</p><h2 id="Rate-limiting-individual-operations"><a href="#Rate-limiting-individual-operations" class="headerlink" title="Rate limiting individual operations"></a>Rate limiting individual operations</h2><p>The simplest form of rate limiting is “1 operation per N seconds”. This one is<br>straightforward, but first we need a building block — the promise counterpart<br>of <code>setTimeout</code>:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> resolveAfter = <span class="function"><span class="params">ms</span> =&gt;</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="params">ok</span> =&gt;</span> <span class="built_in">setTimeout</span>(ok, ms));</span><br></pre></td></tr></table></figure><p><code>resolveAfter</code> is self-explanatory: it returns a promise that resolves after<br>the specified time has elapsed. Now, for the actual rate limiter:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">rateLimit1</span>(<span class="params">fn, msPerOp</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> wait = <span class="built_in">Promise</span>.resolve();</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">...a</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// We use the queue tail in wait to start both the</span></span><br><span class="line">    <span class="comment">// next operation and the next delay</span></span><br><span class="line">    <span class="keyword">const</span> res = wait.then(<span class="function">() =&gt;</span> fn(...a));</span><br><span class="line">    wait = wait.then(<span class="function">() =&gt;</span> resolveAfter(msPerOp));</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now we can, as usual, wrap the promise and call with no worries, the operations<br>are magically delayed:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> slowFetch = rateLimit1(fetch, <span class="number">1000</span>);</span><br><span class="line"><span class="built_in">Promise</span>.all(urls.map(<span class="function"><span class="params">u</span> =&gt;</span> slowFetch(u)))</span><br><span class="line">  .then(<span class="function"><span class="params">raw</span> =&gt;</span> <span class="built_in">Promise</span>.all(raw.map(<span class="function"><span class="params">p</span> =&gt;</span> p.json())))</span><br><span class="line">  .then(<span class="function"><span class="params">pages</span> =&gt;</span> <span class="built_in">console</span>.log(pages));</span><br></pre></td></tr></table></figure><p>The 1-rate-limiter can also be elegantly implemented on top of serializer<br>with the pitfall of unnecessarily delaying the first operation:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">rateLimit1</span>(<span class="params">fn, msPerOp</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> wait = serializePromises(<span class="function">() =&gt;</span> resolveAfter(msPerOp));</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">...a</span>) =&gt;</span> wait().then(<span class="function">() =&gt;</span> fn(...a));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Rate-limiting-multiple-operations"><a href="#Rate-limiting-multiple-operations" class="headerlink" title="Rate limiting multiple operations"></a>Rate limiting multiple operations</h2><p>Many APIs feature soft rate limits instead: they allow <code>M request per N seconds</code>.<br>That is not equivalent to <code>1 request per N/M seconds</code>! Converting the multiple<br>rate limit into individual one does fulfil the rate limit, but is overly harsh<br>and non-optimal. Let’s see this through examples.</p><h3 id="Difference-from-individual-rate-limit-by-example"><a href="#Difference-from-individual-rate-limit-by-example" class="headerlink" title="Difference from individual rate limit, by example"></a>Difference from individual rate limit, by example</h3><p>Suppose you’re flying a plane, and the airline allows 10 kg of luggage per<br>passenger. If you’re travelling with a girl, and have one 16-kg bag with both<br>your things. At the check-in desk you’re asked to take out half the stuff in<br>your bag to make two 8-kg items. While formally correct, it feels idiotic —<br>you still add the exact same weight to the plane! But now, why would you enforce<br>such a stupid restriction on your own operations if you can do better?</p><p>Closer to the topic, let’s try 2-req-per-2-sec rate limit for operations<br>lasting 2 seconds. If you immediately fire 2 requests, you’re done in 2 seconds:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">----| 2 seconds, all done!</span><br><span class="line">----|</span><br></pre></td></tr></table></figure><p>Converting this into 1-req-per-1-sec delays the second request by 1s, and<br>now the same 2 requests take 3 seconds! You just lost a second for no reason.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">----  | 3 seconds</span><br><span class="line">  ----|</span><br></pre></td></tr></table></figure><h3 id="Understanding"><a href="#Understanding" class="headerlink" title="Understanding"></a>Understanding</h3><p>To understand what we should do, let’s have a closer look at the 1-rate-limit.<br>We essentially make a queue of promises that never resolve closer than <code>delay</code><br>apart. We use the resolutions to start the next operations, and don’t care<br>about its termination at all:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*--*--     *--*--</span><br></pre></td></tr></table></figure><p>This view extends to N-rate-limit: create N independent queues and put these<br>into a circular queue (yes, a queue of queues makes a good <em>in Soviet Russia</em><br>joke):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">*--*-- *--*--</span><br><span class="line"> *-- *--*--  *--</span><br><span class="line"> *--  *-- *--    *--</span><br></pre></td></tr></table></figure><p>The individual queues are unchanged, and never fire more than 1 operation per N<br>seconds. Thus, M queues can fire at most M operations during the window.</p><h3 id="Implementing"><a href="#Implementing" class="headerlink" title="Implementing"></a>Implementing</h3><p>With this plan in mind, we can generalize the implementation:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">rateLimit</span>(<span class="params">fn, windowMs, reqInWindow = <span class="number">1</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">// A battery of 1-rate-limiters</span></span><br><span class="line">  <span class="keyword">const</span> queue = _.range(reqInWindow).map(<span class="function">() =&gt;</span> rateLimit1(fn, windowMs));</span><br><span class="line">  <span class="comment">// Circular queue cursor</span></span><br><span class="line">  <span class="keyword">let</span> i = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">...a</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// to enqueue, we move the cursor...</span></span><br><span class="line">    i = (i + <span class="number">1</span>) % reqInWindow;</span><br><span class="line">    <span class="comment">// and return the rate-limited operation.</span></span><br><span class="line">    <span class="keyword">return</span> queue[i](...a);</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Preventing-queue-overflow"><a href="#Preventing-queue-overflow" class="headerlink" title="Preventing queue overflow"></a>Preventing queue overflow</h2><p>Just as before, we run into problems if the operations are consistently inserted<br>into the queue faster than the rate limit. The solution is the same: once the<br>queue exceeds the specified number of items, we immediately reject the incoming<br>operations.</p><h2 id="Combining-with-concurrency-limiting"><a href="#Combining-with-concurrency-limiting" class="headerlink" title="Combining with concurrency limiting"></a>Combining with concurrency limiting</h2><p>Now that we know how to limit both the rate and the number of simultaneously<br>running operations, and since neither is a substitute for another, we want a<br>way to combine the two limits. But can we build the joint rate/concurrency<br>limiter by composing the primitive limiters? Turns out we can, but should carefully<br>choose the order.</p><p><code>rateLimit(concurrencyLimit(fetch, N), ms)</code>, limits the rate at which the<br>operations enter the concurrency-limit queue. Serialized (1-concurrent) promises<br>rate-limited to 1 second break this combination. Suppose the first operation runs for<br>2 seconds, and during that time we throw 2 fast operations, O_2 and O_3 (say,<br>10 ms each) into the serializer. Instead of waiting for 1 second, the O_3 starts<br>right after O_2 completes, or 10ms after it starts, breaking the rate limit.</p><p><code>concurrencyLimit(rateLimit(fetch, ms), N)</code> limits the number of operations in<br>the rate-limit queue. Since the rate limiter only sees N operations at a time,<br>it has no chance to fire more than N, which is exactly what we want.<br>Hence, <strong>Chaining Rule 1: limit concurrency before rate.</strong></p><h2 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h2><p>The classic and most appropriate rate-limiting use case is for API requests.<br>But now that you know the pattern, you will see it in your own tasks and,<br>hopefully, use it ;-)</p><p>Promise-based rate limiting is a great way to quickly hack together a safe API<br>wrapper without depending on the underlying HTTP / TCP / WebSocket client.</p><p>Frankly, other use cases I can come up with off the top of my head (render<br>throttling and preventing too many e-mail notifications) are better served by<br>batching. Maybe, you’ll have better luck.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>We’ve learnt to rate-limit promise-based APIs, both for the simple<br>“1-action-per-N-seconds” and the more general M-actions case. Together with the<br>previously discussed concurrency limiter, these patterns allow us to build robust<br>service gateways with node.js, safely call external APIs and do all the other<br>things you come up with.</p><p>Planning note: I’ve decided to throw away the excessively tricky part on load<br>balancing and go with super fun and useful posts on <em>batching</em> and <em>handling failure</em>.<br>I have RSS now, so be sure to stay tuned!</p><p><strong>Advanced Promise Coordination Series</strong></p><ul><li><a href="/2018/06/20/serialize-promises/">Serialization and Concurrency Limiting</a></li><li><a href="/2018/07/07/rate-limit-promises/">Rate Limiting</a></li></ul></div><span class="share"><div><a target="_blank" rel="noopener" href="https://twitter.com/share?url=https://thoughtspile.github.io/2018/07/07/rate-limit-promises/&text=Advanced Promise Coordination: Rate Limiting by @thoughtspile">Tweet</a></div><div id="share-button"><a>Share</a></div><div><a target="_blank" rel="noopener" href="https://twitter.com/search?q=https://thoughtspile.github.io/2018/07/07/rate-limit-promises/">Discuss on Twitter</a></div></span><div class="post-related">More? <a class="tag-link-link" href="/">All articles ever</a> <a class="tag-link-link" href="/tags/high-availability/" rel="tag">high availability</a> <a class="tag-link-link" href="/tags/javascript/" rel="tag">javascript</a> <a class="tag-link-link" href="/tags/programming/" rel="tag">programming</a> <a class="tag-link-link" href="/tags/promises/" rel="tag">promises</a></div><div class="post-actions">Written in <time datetime="2018-07-07T07:11:13.000Z" itemprop="datePublished">2018</time> by&nbsp;your friend, <a href="/">Vladimir.</a> Follow&nbsp;me on&nbsp;<a href="https://twitter.com/thoughtspile" target="_blank">Twitter</a> to&nbsp;get post updates. I&nbsp;have <a href="/atom.xml">RSS,</a> too. And you can <a class="bmc link--bare" target="_blank" rel="noopener" href="https://buymeacoffee.com/thoughtspile">buy me a coffee!</a></div><div class="post-siblings"><a class="link--bare" href="/2018/06/20/serialize-promises/"><div class="post-siblings__direction">Older</div><span class="link__text">Advanced Promises Coordination: Serialization and Concurrency Limiting</span> </a><a class="link--bare" href="/2018/07/14/docx-is-a-zip-archive/"><div class="post-siblings__direction">Newer</div><span class="link__text">Quick Tip: docx is a zip Archive</span></a></div></article></div></body></html><script type="text/javascript">!function(e,a,t,n,g,c){e.GoogleAnalyticsObject=n,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=+new Date,g=a.createElement(t),c=a.getElementsByTagName(t)[0],g.async=1,g.src="//www.google-analytics.com/analytics.js",c.parentNode.insertBefore(g,c)}(window,document,"script","ga"),ga("create","UA-121445688-1","auto"),ga("send","pageview")</script><script src="/js/share-7bc8702b14501402f6b7d1cf149776a9.js"></script>